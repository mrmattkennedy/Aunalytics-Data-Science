{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First row is headers, so just simple import on the csv data using pandas\n",
    "train_csv = pd.read_csv(\"au_train.csv\")\n",
    "test_csv = pd.read_csv(\"au_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the data, there are 14 variable columns, as well as the \"class\", or target column.\n",
    "We want to convert object  columns to discrete data. We can do this by hand, but an easier way is to use pandas builtin Categorical functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert object columns to discrete numerical values\n",
    "for col in train_csv:\n",
    "    if train_csv[col].dtype == np.dtype('object'):\n",
    "        temp_col = pd.Categorical(train_csv[col])\n",
    "        temp_col = temp_col.codes\n",
    "        train_csv[col] = temp_col\n",
    "\n",
    "#Do the same for the test data\n",
    "for col in test_csv:\n",
    "    if test_csv[col].dtype == np.dtype('object'):\n",
    "        temp_col = pd.Categorical(test_csv[col])\n",
    "        temp_col = temp_col.codes\n",
    "        test_csv[col] = temp_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the data for tensorflow and start making the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pop the class columns off each dataset to save as targets for each\n",
    "train_y = train_csv.pop('class')\n",
    "test_y = test_csv.pop('class')\n",
    "\n",
    "#Load train csv into tensor, then shuffle and create batches\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_csv.values, train_y.values))\n",
    "train_dataset = train_dataset.shuffle(len(train_csv)).batch(50)\n",
    "\n",
    "#Load test csv into tensor\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_csv.values, test_y.values))\n",
    "test_dataset = test_dataset.batch(len(test_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dense(250, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 766.8135 - accuracy: 0.6766\n",
      "Epoch 2/5\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 282.6711 - accuracy: 0.6815\n",
      "Epoch 3/5\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 168.3123 - accuracy: 0.6819\n",
      "Epoch 4/5\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 73.9150 - accuracy: 0.6900\n",
      "Epoch 5/5\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 51.5156 - accuracy: 0.6851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d4b925cd60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 47.4002 - accuracy: 0.7939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[47.40016555786133, 0.7939316034317017]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
